{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent-Based Modeling of Collective Emotions: Implementing the Cyberemotions Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains an implementation of the _Cyberemotions_ agent-based modeling framework in Python (version 3.7) that abstracts the emergence of collective emotions and the spread of emotional information in social media, following the formalization of [Garcia et al. (2016)](http://dx.doi.org/10.1098/rsos.160059)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard model parameters are hardcoded, unless otherwise specified, as follows:\n",
    "\n",
    "| Parameter | Short | Value | Constant\n",
    "|---|---|---|---|\n",
    "| Valence baseline | *b* | 0.056 | BASE_V |\n",
    "| Arousal baseline | *d* | -0.442 | BASE_A |\n",
    "| Valence decay | *&gamma;<sub>v</sub>* | 0.367 | DECAY_V |\n",
    "| Arousal decay | *&gamma;<sub>a</sub>* | 0.414 | DECAY_A |\n",
    "| Amplitudes | *A<sub>v</sub>* | 0.3 | AMP_V |\n",
    "|| *A<sub>a</sub>* | 0.3 | AMP_A |\n",
    "| Arousal threshold | *&tau;* | 0 | THRESH_A |\n",
    "| Down-regulation factor | *k<sub>v</sub>* | 0.38 | FACTOR_V |\n",
    "|| *k<sub>a</sub>* | 0.45 | FACTOR_A |\n",
    "| Satiation factor | *c* | 1.0 | SAT_C |\n",
    "| Valence coefficients | *b<sub>0</sub>* | 0.14 | COEFF_B0 |\n",
    "|| *b<sub>1</sub>* | 0 | COEFF_B1 |\n",
    "|| *b<sub>2</sub>* | 0.057 | COEFF_B2 |\n",
    "|| *b<sub>3</sub>* | -0.047 | COEFF_B3 |\n",
    "| Arousal coefficients | d<sub>0</sub> | 0.178 | COEFF_D0 |\n",
    "|| *d<sub>1</sub>* | 0.14469 | COEFF_D1 |\n",
    "|| *d<sub>2</sub>* | 0 | COEFF_D2 |\n",
    "|| *d<sub>3</sub>* | 0 | COEFF_D3 |\n",
    "| Field charge | *h* | 0 | CHARGE_H |\n",
    "| Field decay | *&gamma;<sub>h</sub>* | 0.7 | DECAY_H |\n",
    "| Field impact | *s* | 0.1 | IMPACT_H |\n",
    "\n",
    "Satiation factor _c_ and field impact _s_ can be set using optional script arguments or as input to the `run()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model design\n",
    "\n",
    "The following section documents the code of the implemented model. **Settings** define standard number of model runs, agents, and time steps. **Parameters** set the constant values the model is run with. **Entities** describes the agent and the communication field as entities of their respective class, including the methods they go through: perception, expression, satiaion, relaxation (agents); and communication (field). **Schedule** the order of which the classes are called and their methods are executed. **Running the model** defines a model class that incorporates entities and schedule, in order to run the model at the given settings and parameters. **Storing the data** saves the output data in the feather format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_runs = 1 # Running the model once by default\n",
    "no_agents = 150 # Arbitrary value\n",
    "no_steps = 150 # Test runs rarely showed a model running for more than 100\n",
    "               # time steps, and hence this should be an appropriate\n",
    "               # maximum that does not cause premature abortion of a run\n",
    "\n",
    "if __name__ == \"__main__\" and '__file__' in globals():\n",
    "# Checking if there are arguments given and adjusting the settings accordingly:\n",
    "    if len(sys.argv) > 2:\n",
    "        no_runs = int(sys.argv[1])\n",
    "        no_agents = int(sys.argv[2])\n",
    "        no_steps = 150\n",
    "\n",
    "MODEL_RUNS = no_runs # Number of times the model is run\n",
    "AGENTS = no_agents # Number of agents at the start of the simulation\n",
    "TIME = no_steps # Maximum number of time steps before the simulation ends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_V = 0.056 # Valence baseline ... b\n",
    "BASE_A = -0.442 # Arousal baseline ... d\n",
    "\n",
    "THRESH_A = 0.0 # Arousal threshold ... tau\n",
    "\n",
    "DECAY_V = 0.367 # Valence decay ... gamma_v\n",
    "DECAY_A = 0.414 # Arousal decay ... gamma_a\n",
    "AMP_V = 0.3 # Valence amplitude of stochastic shocks ... A_v\n",
    "AMP_A = 0.3 # Arousal amplitude of stochastic shocks ... A_a\n",
    "FACTOR_V = 0.38 # Valence down-regulation factor ... k_v\n",
    "FACTOR_A = 0.45 # Arousal down-regulation factor ... k_a\n",
    "\n",
    "COEFF_B0 = 0.14 # Valence coefficient ... b_0\n",
    "COEFF_B1 = 0 # Valence coefficient ... b_1\n",
    "COEFF_B2 = 0.057 # Valence coefficient ... b_2\n",
    "COEFF_B3 = -0.047 # Valence coefficient ... b_3\n",
    "\n",
    "COEFF_D0 = 0.178 # Arousal coefficient ... d_0\n",
    "COEFF_D1 = 0.14469  # Arousal coefficient ... d_1\n",
    "COEFF_D2 = 0  # Arousal coefficient ... d_2\n",
    "COEFF_D3 = 0  # Arousal coefficient ... d_3\n",
    "\n",
    "CHARGE_H = 0 # Initial charge of the field ... h\n",
    "DECAY_H = 0.7 # Field decay ... gamma_h\n",
    "\n",
    "impct = 0.1 \n",
    "# Note: Test runs showed with standard value s = 0.1 the model only behaves as\n",
    "# expected with 150 agents. Scaling is needed and can be set using arguments.\n",
    "sttn = 1.0\n",
    "\n",
    "if __name__ == \"__main__\" and '__file__' in globals():\n",
    "# Checking if there are arguments given and adjusting the parameters\n",
    "# accordingly:\n",
    "    if len(sys.argv) > 3:\n",
    "        impct = float(sys.argv[3]) / AGENTS\n",
    "        sttn = float(sys.argv[4])\n",
    "\n",
    "IMPACT_H = impct # Impact of agent expressions on the field ... s\n",
    "SAT_C = sttn # Saturation factor ... c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    '''Class describing one agent instance and its state variables.'''\n",
    "    def __init__(self):\n",
    "        self.bsln_v = np.random.normal(BASE_V, 0.1) # Valence baseline\n",
    "        self.bsln_a = np.random.normal(BASE_A, 0.1) # Arousal baseline\n",
    "        # Note: Spread of the normal distrution should not cause valence or\n",
    "        # arousal baselines to lie above 1 or below -1\n",
    "        self.vlnc = self.bsln_v # Setting initial valence to baseline value\n",
    "        self.arsl = self.bsln_a # Setting initial arousal to baseline value\n",
    "        self.thrshld = THRESH_A # Arousal threshold\n",
    "        self.hstry_v = [] # History of valence values at each time step\n",
    "        self.hstry_a = [] # History of arousal values at each time step\n",
    "\n",
    "    def perception(self, field):\n",
    "        '''Method changing the agent state variables given their perception of\n",
    "        the field, using its state variable as input and adding stochasticity\n",
    "        to global change coefficients'''\n",
    "        self.vlnc += field.sgn * (COEFF_B0 +\n",
    "                                  COEFF_B1 * self.vlnc +\n",
    "                                  round((COEFF_B2 * self.vlnc), 9) ** 2 +\n",
    "                                  round((COEFF_B3 * self.vlnc), 9) ** 3)\n",
    "        self.arsl += field.abslt * (COEFF_D0 +\n",
    "                                    COEFF_D1 * self.arsl +\n",
    "                                    round((COEFF_D2 * self.arsl), 9) ** 2 +\n",
    "                                    round((COEFF_D3 * self.arsl), 9) ** 3)\n",
    "        # Note: Coefficients B3 and D3 sometimes caused the program not to\n",
    "        # execute during first test runs due to an \"result too large\" error.\n",
    "\n",
    "        # Stochastic shocks triggering agent interaction:\n",
    "        self.vlnc += AMP_V * np.random.uniform(-1, 1)\n",
    "        self.arsl += AMP_A * np.random.uniform(-1, 1)\n",
    "\n",
    "    def expression(self):\n",
    "        '''Method checking if an agent expresses its emotions, down-regulating\n",
    "        them using global factors, and returning information whether it is\n",
    "        a positive or negative emotion, or none at all.'''\n",
    "        if self.arsl >= self.thrshld:\n",
    "            emotion = np.sign(self.vlnc)\n",
    "            self.vlnc = ((self.vlnc - self.bsln_v) * FACTOR_V + self.bsln_v)\n",
    "            self.arsl = ((self.arsl - self.bsln_a) * FACTOR_A + self.bsln_a)\n",
    "        else:\n",
    "            emotion = None\n",
    "\n",
    "        return emotion\n",
    "\n",
    "    def satiation(self, sttn):\n",
    "        '''Method checking whether an agent drops out of the simulation given\n",
    "        the current emotional state and returning a boolean value.'''\n",
    "        probability = np.absolute(self.arsl ** 2) * sttn\n",
    "        chance = np.random.uniform(0, 1)\n",
    "        return bool(chance <= probability)\n",
    "\n",
    "    def relaxation(self):\n",
    "        '''Method relaxing the emotions of an agent towards their respective\n",
    "        baselines, using the global decay parameter.'''\n",
    "        self.vlnc += -1 * DECAY_V * (self.vlnc - self.bsln_v)\n",
    "        self.arsl += -1 * DECAY_A * (self.arsl - self.bsln_a)\n",
    "\n",
    "    def collect_data(self):\n",
    "        '''Method collecting the agent state variables in a list.'''\n",
    "        self.hstry_v.append(round(self.vlnc, 2))\n",
    "        self.hstry_a.append(round(self.arsl, 2))\n",
    "\n",
    "class Field:\n",
    "    '''Class describing the communication field and its state variables'''\n",
    "    def __init__(self):\n",
    "        self.abslt = CHARGE_H # Absolute value of the charge of the field\n",
    "        self.sgn = CHARGE_H # Sign of the charge of the field\n",
    "        self.hstry_h = [self.abslt] # History of the field at each time step\n",
    "\n",
    "    def communication(self, positive_expressions, negative_expressions, impct):\n",
    "        '''Method changing the field state variable using positive and\n",
    "        negative emotional expressions as input, adding decay over time using\n",
    "        a global parameter.'''\n",
    "        absolute_expressions = positive_expressions + negative_expressions\n",
    "        sign_expressions = positive_expressions - negative_expressions\n",
    "\n",
    "        self.abslt += (-1 * DECAY_H * self.abslt +\n",
    "                       impct * absolute_expressions)\n",
    "        self.sgn += (-1 * DECAY_H * self.sgn +\n",
    "                     impct * sign_expressions)\n",
    "\n",
    "    def collect_data(self):\n",
    "        '''Method collecting the field state variable in a list.'''\n",
    "        self.hstry_h.append(round(self.sgn, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    '''Class describing the initialization of one instance of a model run and\n",
    "    its schedule.'''\n",
    "    def __init__(self, agents):\n",
    "        self.actv_agnts = [Agent() for agent in range(agents)]\n",
    "        self.inctv_agnts = []\n",
    "        self.fld = Field()\n",
    "        self.hstry_A = [len(self.actv_agnts)]\n",
    "        self.hstry_N = [0]\n",
    "        self.tm_stps = [0]\n",
    "\n",
    "    def schedule(self, timesteps, sttn, impct):\n",
    "        '''Method scheduling the agent and field processes, including their\n",
    "        data collection and returning a data frame.'''\n",
    "        # The simulation ends when all the agents dropped out, or when the\n",
    "        # maximum number of time steps was reached:\n",
    "        step = 0\n",
    "        while step < timesteps and len(self.actv_agnts) > 0:\n",
    "            step += 1\n",
    "            # Keeping track of the number of expressions during each time step:\n",
    "            positive_expressions = 0\n",
    "            negative_expressions = 0\n",
    "\n",
    "            for agent in self.actv_agnts:\n",
    "                agent.perception(self.fld)\n",
    "                agent.collect_data()\n",
    "                # Note: Agent data is collected once per time step and this\n",
    "                # seems to be the most useful moment, because it captures the\n",
    "                # emotional high points of the agents.\n",
    "                emotion = agent.expression()\n",
    "                #agent.collect_data()\n",
    "                if emotion == 1:\n",
    "                    positive_expressions += 1\n",
    "                elif emotion == -1:\n",
    "                    negative_expressions += 1\n",
    "                if agent.satiation(sttn):\n",
    "                    self.inctv_agnts.append(agent)\n",
    "                    self.actv_agnts.remove(agent)\n",
    "                agent.relaxation()\n",
    "                #agent.collect_data()\n",
    "\n",
    "            # After all the agents took their actions, the field is now\n",
    "            # updated:\n",
    "            self.fld.communication(positive_expressions,\n",
    "                                   negative_expressions,\n",
    "                                   impct)\n",
    "            self.fld.collect_data()\n",
    "            # Collecting data for expressions, number of agents, and time:\n",
    "            self.hstry_A.append(len(self.actv_agnts))\n",
    "            self.hstry_N.append(positive_expressions + negative_expressions)\n",
    "            self.tm_stps.append(step)\n",
    "            # Making sure the order the agents act in is not the same at every\n",
    "            # time step by shuffling the agent list:\n",
    "            np.random.shuffle(self.actv_agnts)\n",
    "\n",
    "        for agent in self.actv_agnts:\n",
    "            self.inctv_agnts.append(agent)\n",
    "            self.actv_agnts.remove(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(runs, agents, impct=IMPACT_H, sttn=SAT_C):\n",
    "    '''Function running the model with the input number of agents for the input\n",
    "    number of time steps, returning a clean dataframe of all model data,\n",
    "    including data on agent and field variables.'''\n",
    "    print(\"Starting \" + str(runs) + \" model run(s)... (agents=\"\n",
    "          + str(agents) + \", s=\" + str(round(impct, 2)) + \", c=\"\n",
    "           + str(sttn) + \")\")\n",
    "    data = pd.DataFrame()\n",
    "    model_runs = [Model(agents) for model in range(runs)]\n",
    "    run = 0\n",
    "    dataset = pd.DataFrame()\n",
    "    for model in model_runs:\n",
    "        model.schedule(TIME, impct, sttn)\n",
    "        for agent in model.inctv_agnts:\n",
    "            data = pd.DataFrame([pd.Series(agent.hstry_v, name=\"v\"),\n",
    "                                pd.Series(agent.hstry_a, name=\"a\")])\n",
    "            data = data.groupby(by=data.index, axis=0).mean()\n",
    "\n",
    "        data = data.append([pd.Series([run], name=\"Run\"),\n",
    "                            pd.Series([agents], name=\"Agents\"),\n",
    "                            pd.Series(model.tm_stps, name=\"Step\"),\n",
    "                            pd.Series([impct], name=\"s\"),\n",
    "                            pd.Series([sttn], name=\"c\"),\n",
    "                            pd.Series(model.hstry_A, name=\"A\"),\n",
    "                            pd.Series(model.hstry_N, name=\"N\"),\n",
    "                            pd.Series(model.fld.hstry_h, name=\"h\")])\n",
    "        data = data.transpose()[[\"Run\", \"Agents\", \"s\", \"c\", \"Step\",\n",
    "                                 \"v\", \"a\", \"A\", \"N\",\"h\"]]\n",
    "        data[[\"Agents\", \"Run\",\n",
    "              \"s\", \"c\"]] = data[[\"Agents\", \"Run\",\n",
    "                                 \"s\", \"c\"]].ffill()\n",
    "        run +=1\n",
    "        dataset = dataset.append(data, ignore_index=True)\n",
    "\n",
    "    print(\"...model run(s) complete!\")\n",
    "    global FILENAME\n",
    "    FILENAME = str(\"data/cyberemotions-\" + str(runs) + \"x\" + \"-agents=\"\n",
    "                   + str(agents) + \",s=\" + str(round(impct, 2))\n",
    "                   + \",c=\" + str(sttn) + \"-\" + str(int(time.time()))\n",
    "                   + \".feather\")\n",
    "    # Note: Using an Unix timestamp to guarantee unique file names to avoid\n",
    "    # overwriting old results of same settings simulations.\n",
    "    return dataset\n",
    "\n",
    "if __name__ == \"__main__\" and '__file__' in globals():\n",
    "    DATA = run(MODEL_RUNS, AGENTS, IMPACT_H, SAT_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(data, filename):\n",
    "    '''Function to save a dataframe to a feather file, accepting the collected\n",
    "    model data and a filename as input. Note: A global filename is generated by\n",
    "    the run function that includes model settings and parameters.'''\n",
    "    print(\"Saving model data... (filename: \" + filename + \")\")\n",
    "    data.to_feather(filename)\n",
    "    print(\"...saving successful!\")\n",
    "\n",
    "if __name__ == \"__main__\" and '__file__' in globals():\n",
    "    save(DATA, FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can be run by simply calling the `run(number_of_runs, number_of_agents, satiation_factor, impact_factor)` function. It returns a dataframe that contains model data for each time step of each model run with the following pattern:\n",
    "\n",
    "| Run | Agents | s | c | Step | v | a | A | N | h |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| Model run | Initial agents | Impact parameter | Satiation parameter | Timestep | Agent valence | Agent arousal | Active agents | Expressions | Field charge |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run(number_of_runs, number_of_agents, satiation_factor, impact factor)\n",
    "data = run(1, 150, 0.1, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(data):\n",
    "    '''Function to take model data and generate plots that visualize agent\n",
    "    valence, agent arousal, field charge, number of agent expressions, and\n",
    "    number of agents remaining in the simulation at every given time step.'''\n",
    "    fig = plt.figure(figsize=(6,12))\n",
    "    ax, ax1, ax2 = fig.add_subplot(311), fig.add_subplot(312), fig.add_subplot(313)\n",
    "\n",
    "    df = data.dropna().drop(columns=[\"Run\", \"Agents\", \"s\", \"c\"]).groupby(\"Step\").mean()\n",
    "\n",
    "    df.plot(y=\"v\", xlim=(0,50), c=\"b\", grid=True, label=\"Valence\", ax=ax)\n",
    "    df.plot(y=\"a\", xlim=(0,50), c=\"r\", grid=True, label=\"Arousal\", ax=ax)\n",
    "    df.plot(y=\"h\", xlim=(0,50), c=\"g\", grid=True, label=\"Field charge\", ax=ax1)\n",
    "    df.plot(y=\"A\", xlim=(0,50), c=\"c\", grid=True, label=\"Agents\", ax=ax2)\n",
    "    df.plot(y=\"N\", xlim=(0,50), c=\"m\", grid=True, label=\"Expressions\", ax=ax2)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
